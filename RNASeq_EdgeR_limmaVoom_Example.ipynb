{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNAseq analysis using edgeR and limma voom \n",
    "#### created by Charity Washam and Stephanie Byrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data has been trimmed, aligned to the reference genome, and counts matrix generated. \n",
    "### The first step of Differential Expression Analysis is to load the sample information and the counts matrix.\n",
    "#### nf-core RNAseq pipeline shows the workflow to generate the counts matrix\n",
    "**Reference:**  doi: 10.5281/zenodo.1400710 </br>\n",
    "Ewels PA, Peltzer A, Fillinger S, Alneberg JA, Patel H, Wilm A, Garcia MU, Di Tommaso P, Nahnsen S. nf-core: Community curated bioinformatics pipelines. bioRxiv. 2019. p. 610741. doi: 10.1101/610741. \n",
    "\n",
    "<img src =\"https://raw.githubusercontent.com/nf-core/rnaseq/3.8.1/docs/images/nf-core-rnaseq_metro_map_grey.png\" alt =\"nf-core\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create conda environment in Terminal \n",
    "conda create -n RNASeq\n",
    "conda activate RNASeq\n",
    "\n",
    "conda install r-base bioconductor-edger r-matrixStats bioconductor-annotationdbi bioconductor-org.mm.eg.db bioconductor-glimma -c conda-forge -c bioconda -c r -c defaults\n",
    "conda install jupyterlab -c conda-forge -c bioconda -c defaults\n",
    "conda install r-irkernel -c conda-forge -c bioconda -c defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To install R Kernel for the Jupyter Notebook, use the following command from the PSSC Labs terminal. \n",
    "# open R in terminal\n",
    "R\n",
    "install.packages(\"devtools\")\n",
    "devtools::install_github(\"IRkernel/IRkernel\")\n",
    "IRkernel::installspec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if packages have not been installed using conda\n",
    "# Install necessary packages into R environment\n",
    "install.packages(\"matrixStats\")\n",
    "install.packages(\"BiocManager\")\n",
    "library(\"BiocManager\")\n",
    "BiocManager::install(\"edgeR\", quietly=TRUE)\n",
    "BiocManager::install(\"AnnotationDbi\", quietly=TRUE)\n",
    "BiocManager::install(\"org.Mm.eg.db\", quietly=TRUE)\n",
    "BiocManager::install(\"Glimma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(edgeR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import targets and counts\n",
    "# load example data\n",
    "targets <- read.csv(\"targets.csv\", header=TRUE, stringsAsFactors=FALSE)\n",
    "targets\n",
    "\n",
    "# Load example data\n",
    "GenewiseCounts <- read.csv(\"htseq_counts_12.csv\", header=TRUE, row.names=1, stringsAsFactors=FALSE)\n",
    "head(GenewiseCounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We must define the sample group as factors and set the levels option so the group is not changed to alphabetical order. Also, define the batch column or any other factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define main factors for the analysis (group main factor for analysis, batch, etc)\n",
    "targets$group <- factor(targets$group, levels=c(unique(targets$group)))\n",
    "table(targets$group)\n",
    "levels(targets$group)\n",
    "\n",
    "### This data does not include a batch but has different tissues\n",
    "targets$batch <- factor(as.character(targets$batch), levels=c(unique(targets$batch)))\n",
    "table(targets$batch)\n",
    "levels(targets$batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data.frame with factors (potential factors for the analysis)\n",
    "#my_targets <- data.frame(group=targets$group, batch=targets$batch)\n",
    "\n",
    "my_targets <- data.frame(group=targets$group, tissue=targets$tissue)\n",
    "rownames(my_targets) <- targets$sample\n",
    "my_targets\n",
    "\n",
    "table(my_targets$group)\n",
    "table(my_targets$tissue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DGEList() = Creates a DGEList object from a table of counts (rows=features, columns=samples), group indicator for each column, library size (optional) and a table of feature annotation (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(\"DGEList-class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DGEList()\n",
    "y <- DGEList(counts=GenewiseCounts, group=  targets$group, genes=rownames(GenewiseCounts), remove.zeros=FALSE)\n",
    "colnames(y$genes)[1] <- \"ensembl_id\"\n",
    "head(y$counts)[,1:5]\n",
    "head(y$genes)\n",
    "head(y$samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the gene annotation from the Mus musculus database and add to the DGEList object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(AnnotationDbi, quietly=TRUE)\n",
    "library(org.Mm.eg.db, quietly=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the database keytpyes for the specific spelling of IDs\n",
    "org.Mm.eg.db\n",
    "keytypes(org.Mm.eg.db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### change the keytype since the input counts matrix includes ENSEMBL ids and not SYMBOLs \n",
    "\n",
    "y$genes$ENSEMBL  <- mapIds(org.Mm.eg.db, keys=rownames(y$genes), keytype = \"SYMBOL\", column=\"ENSEMBL\", multiVals=\"first\")\n",
    "y$genes$ENTREZID <- mapIds(org.Mm.eg.db, keys=rownames(y$genes), keytype = \"SYMBOL\", column=\"ENTREZID\", multiVals=\"first\")\n",
    "y$genes$SYMBOL   <- mapIds(org.Mm.eg.db, keys=rownames(y$genes), keytype = \"SYMBOL\", column=\"SYMBOL\", multiVals=\"first\")\n",
    "y$genes$GENENAME <- mapIds(org.Mm.eg.db, keys=rownames(y$genes), keytype = \"SYMBOL\", column=\"GENENAME\", multiVals=\"first\")\n",
    "\n",
    "#y$genes$ENSEMBL  <- mapIds(org.Mm.eg.db, keys=rownames(y$genes), keytype = \"ENSEMBL\", column=\"ENSEMBL\", multiVals=\"first\")\n",
    "#y$genes$ENTREZID <- mapIds(org.Mm.eg.db, keys=rownames(y$genes), keytype = \"ENSEMBL\", column=\"ENTREZID\", multiVals=\"first\")\n",
    "#y$genes$SYMBOL   <- mapIds(org.Mm.eg.db, keys=rownames(y$genes), keytype = \"ENSEMBL\", column=\"SYMBOL\", multiVals=\"first\")\n",
    "#y$genes$GENENAME <- mapIds(org.Mm.eg.db, keys=rownames(y$genes), keytype = \"ENSEMBL\", column=\"GENENAME\", multiVals=\"first\")\n",
    "\n",
    "# view final imported data\n",
    "head(y$counts)[,1:5]\n",
    "head(y$samples)\n",
    "head(y$genes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter genes that contain zeros in all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example subset\n",
    "# d <- matrix(rnbinom(16,size=1,mu=10),4,4)\n",
    "# rownames(d) <- c(\"a\",\"b\",\"c\",\"d\")\n",
    "# colnames(d) <- c(\"A1\",\"A2\",\"B1\",\"B2\")\n",
    "# d <- DGEList(counts=d,group=factor(c(\"A\",\"A\",\"B\",\"B\")))\n",
    "#d[1:2,]\n",
    "#d[1:2,2]\n",
    "# d[,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## [2] REMOVE GENES WITH ZERO COUNTS\n",
    "\n",
    "# genes with zero counts in all samples\n",
    "zeros <- rowSums(y$counts)==0\n",
    "table(zeros)\n",
    "\n",
    "# keep genes with at least 1 count in 1 sample (i.e. filter genes with zero counts in all samples). \n",
    "keep <- rowSums(y$counts) > 0\n",
    "table(keep)\n",
    "y <- y[keep,, keep.lib.sizes=FALSE]\n",
    "dim(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Dealing with Sequencing Bias: </b>Check raw values such as number of groups, samples, genes to make sure the object size is correct. Check the library size for each sample, which indicates the depth of sequencing. Calculate counts per million.  \n",
    "\n",
    "<p>The differences between the number of readings is due to accidental variations in how much each different library is loaded into the flowcell and sequenced. </p>\n",
    "\n",
    "<p>When loading a multiplexed RNAseq experiment into the flowcell, one quantifies the DNA (the initial RNA is reverse transcribed to DNA) amount for each library, \"normalizes\" the libraries (i.e., dilutes all libraries to the same DNA concentration), and loads the same amount of each library into the flowcell. In an ideal world, all libraries would have the same number of reads, and then no library size normalization would be necessary for the analysis - this is rarely the case, though, and there is substantial reads number variation between libraries. https://www.biostars.org/p/349881/#350181</p>\n",
    "\n",
    "<p> There are multiple bias engaged in RNAseq experiment : <b>library size, genes length, RNA population composition for each condition and genes GC composition.</b>\n",
    "Two bias can be discarded if you compare genes amongst conditions only, because these two are inherent to the gene : <b>genes length and genes GC composition</b></p>\n",
    "    \n",
    "<p><b>genes length :</b> The raw count of two genes cannot compared if gene A is twice longer than gene B. Due to its length, the longest gene will have higher chance to be sequenced than the short one. And in the end, for the same expression level, the longest gene will identify more reads than the shortest one.</p>\n",
    "\n",
    "<p><b>genes GC composition :</b> For two genes with different GC content, the one with the closest GC content to 40% will more likely be sequenced. </p>\n",
    "<p>The others bias are \"technical bias\", due to your sample and sequencing method.\n",
    "<b>library size : </b> The most well know bias. You create two libraries for two conditions with the same RNA composition. The second library works way better than the first one, you get 12 000 000 reads for condition A and 36 000 000 reads for condition B. You will have three times (36 000 000/12 000 000 = 3) more of each RNA in your condition B than your condition A. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/Ld4YH9m/condition-A.png\" alt=\"condition A\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/sgF0PSj/condition-B.png\" alt=\"condition B\">\n",
    "  \n",
    "    \n",
    "<p>Apart from the differences in library depth, an additional problem is that RNASeq frequently have different amounts of different RNA types in them. A simple example could be that you have more rRNA in one sample than in another (lets say 1% vs 20%) if you do not take this into account it would look like the majority of protein coding genes were downregulated simply because they would get a smaller fraction of reads. Such effects is handled by doing a inter-library normalization an analysis build into all the major DE tool workflows. You can read more about this problem here. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce these bias, there are a lot of methods to normalize RNAseq data.\n",
    "\n",
    "<p>Those which I call naive ones :\n",
    "\n",
    "<ul>\n",
    "    <li>Total count</li>\n",
    "    <li>Upper Quartile </li>\n",
    "    <li>RPKM (Reads Per Kilobase per Million, which is not solid enought for cross condition experiment, pub4 & pub5)</li>\n",
    "</ul>\n",
    "</p>\n",
    "\n",
    "Those with a statistical power :\n",
    "\n",
    "For the batch effect\n",
    "<ul>\n",
    "  <li>RLE method (Relative log Expression) like DESeq2 </li>\n",
    "  <li>TMM method (Trimmed Mean of M values) like edgeR </li>\n",
    "</ul>\n",
    "    Plus, the most used rule to normalize gene count :\n",
    "\n",
    "<ul> \n",
    "    <li>negative binomial distribution (edgeR, DESeq2)</li>\n",
    "<li>Add to that a multiple testing correction, to output strong express genes (DESeq2)</li>\n",
    "</ul>\n",
    "    Library size is the major biais and could be handle in DESeq2 using the <b> sizeFactor </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##--------------------\n",
    "##   RAW VARIABLES\n",
    "##--------------------\n",
    "y.raw          <- y\n",
    "ngroups        <- length(unique(y$samples$group)); ngroups\n",
    "nsamples       <- ncol(y); nsamples\n",
    "ngenes         <- nrow(y); ngenes\n",
    "\n",
    "raw_lib        <- y$samples; head(raw_lib)\n",
    "raw_counts     <- y$counts; #dim(raw_counts)\n",
    "raw_cpm        <- cpm(y, prior.count=2);# dim(raw_cpm)\n",
    "raw_lcpm       <- cpm(y, prior.count=2, log=TRUE);# dim(raw_lcpm)\n",
    "raw_anno       <- y$genes; head(raw_anno)\n",
    "raw_L          <- log2(2/(mean(y$samples$lib.size) * 1e-06)); #raw_L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Within-Sample Normalization = Counts per Million (CPM) </b> Read count routinely refers to the number of reads that align to a particular region. Counts per million mapped reads are counts scaled by the number of sequenced fragments multiplied by one million. <b>Transcripts per million (TPM)</b> is a measurement of the proportion of transcripts in a pool of RNA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson.raw_lcpm      <- cor(raw_lcpm, use=\"all.obs\", method=\"pearson\")\n",
    "spearman.raw_lcpm     <- cor(raw_lcpm, use=\"all.obs\", method=\"spearman\")\n",
    "\n",
    "raw_var     <- matrixStats::rowVars(raw_lcpm) # row variance per gene\n",
    "raw_scale   <- t(scale(t(raw_lcpm)))  # scaled lcpm values mean=0, std=1\n",
    "\n",
    "stopifnot(rownames(raw_scale)==rownames(y$genes))\n",
    "stopifnot(rownames(raw_scale)==rownames(y$counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mean, median, min., and max. library sizes\n",
    "L  <- mean(y$samples$lib.size) * 1e-06\n",
    "M  <- median(y$samples$lib.size) * 1e-06\n",
    "Mn <- min(y$samples$lib.size) * 1e-06\n",
    "Mx <- max(y$samples$lib.size) * 1e-06\n",
    "round(c(L, M, Mn, Mx),1)\n",
    "\n",
    "# smallest libraries\n",
    "min_group <- min(table(targets$group))  \n",
    "min_group\n",
    " \n",
    "# calculates the CPM value that corresponds to a count of 10\n",
    "cpm(10, min(y$samples$lib.size))\n",
    "min_cpm <- round(as.numeric(cpm(10, min(y$samples$lib.size))),2)\n",
    "min_cpm \n",
    "\n",
    "keep <- rowSums(cpm(y) > min_cpm) >=  min_group\n",
    "table(keep)\n",
    "\n",
    "y <- y[keep, , keep.lib.sizes=FALSE]\n",
    "dim(y) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The option **keep.lib.sizes=FALSE** causes the library sizes to be recomputed after filtering.\n",
    "#### This is generally recommended, although the effect on the downstream analysis is usually small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##---------------------------\n",
    "## FILTER VARIABLES (y)\n",
    "##---------------------------\n",
    "y.filter           <- y\n",
    "filter_lib         <- y$samples\n",
    "filter_ngenes      <- nrow(y); filter_ngenes\n",
    "filter_anno        <- y$genes; head(filter_anno)\n",
    "head(filter_anno)[1:5,]; dim(filter_anno)\n",
    "filter_counts      <- y$counts\n",
    "filter_cpm         <- cpm(y, prior.count=2)\n",
    "filter_lcpm        <- cpm(y, prior.count=2, log=TRUE)\n",
    "filter_L           <- log2(2/(mean(y$samples$lib.size) * 1e-6)); filter_L \n",
    "\n",
    "pearson.filter_lcpm      <- cor(filter_lcpm, use=\"all.obs\", method=\"pearson\")\n",
    "spearman.filter_lcpm     <- cor(filter_lcpm, use=\"all.obs\", method=\"spearman\")\n",
    "\n",
    "filter_var     <- matrixStats::rowVars(filter_lcpm) # row variance per gene\n",
    "filter_scale   <- t(scale(t(filter_lcpm)))  # scaled lcpm values mean=0, std=1\n",
    "\n",
    "print(\"Saved filtered variables\")\n",
    "\n",
    "stopifnot(rownames(filter_scale)==rownames(y$genes))\n",
    "stopifnot(rownames(filter_scale)==rownames(y$counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Between sample normalization - Trimmed mean of M values (TMM) </b>\n",
    "<p><b> CPM \"normalization\" </b> accounts for library size differences between samples, and produces normalized values that can be compared on an absolute scale (e.g., for filtering). <b>TMM normalization </b> accounts for composition bias, and computes normalization factors for comparing between libraries on a relative scale. <b>CPM</b> normalization doesn't account for composition bias, and <b>TMM</b> normalization doesn't produce normalized values. Thus, you need both steps in the analysis pipeline.  </p>\n",
    "\n",
    "<b>Reference :</b> </br>\n",
    "Robinson, M.D., Oshlack, A. A scaling normalization method for differential expression analysis of RNA-seq data. Genome Biol 11, R25 (2010). https://doi.org/10.1186/gb-2010-11-3-r25 </br>\n",
    "https://support.bioconductor.org/p/69433/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-------------------------------\n",
    "##     TMM NORMALIZATION (y)     \n",
    "##-------------------------------\n",
    "\n",
    "# NORMALIZED DATA (y)\n",
    "y <- calcNormFactors(y, method=\"TMM\")\n",
    "head(y$samples)\n",
    "\n",
    "##---------------------------\n",
    "##   NORM VARIABLES (y)\n",
    "##---------------------------\n",
    "y.norm          <- y\n",
    "norm_lib        <- y$samples\n",
    "norm_lib        <- cbind(y$samples, (y$samples$norm.factors * y$samples$lib.size))\n",
    "colnames(norm_lib) <- c(\"group\", \"old.lib.size\", \"norm.factors\", \"lib.size\"); head(norm_lib)\n",
    "\n",
    "norm_factor     <- y$samples$norm.factors\n",
    "norm_anno       <- y$genes\n",
    "norm_counts     <- y$counts\n",
    "norm_cpm        <- cpm(y, prior.count=2, normalized.lib.sizes = TRUE)\n",
    "norm_lcpm       <- cpm(y, prior.count=2, normalized.lib.sizes = TRUE, log=TRUE)\n",
    "norm_L          <- log2(2/(mean(y$samples$lib.size, normalized.lib.sizes=TRUE) * 1e-06)); norm_L \n",
    "\n",
    "pearson.norm_lcpm      <- cor(norm_lcpm, use=\"all.obs\", method=\"pearson\")\n",
    "spearman.norm_lcpm     <- cor(norm_lcpm, use=\"all.obs\", method=\"spearman\")\n",
    "\n",
    "norm_var     <- matrixStats::rowVars(norm_lcpm) # row variance per gene\n",
    "norm_scale   <- t(scale(t(norm_lcpm)))  # scaled lcpm values mean=0, std=1\n",
    "\n",
    "stopifnot(rownames(norm_scale)==rownames(y$genes))\n",
    "stopifnot(rownames(norm_scale)==rownames(y$counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limma voom analysis\n",
    "\n",
    "**Limma** is an R package that was originally developed for differential expression (DE) of microarray data. </br>\n",
    "**Voom** is a function in the limma package that modifies RNA-seq data for use with limma. \n",
    "\n",
    "1. voom method estimates the mean-variance relationship of the log-counts\n",
    "2. generates a precision weight for each observation\n",
    "3. enters these into the limma empirical Bayes analysis\n",
    "\n",
    "count data shows a marked mean-variance relationship. Raw counts show increasing variance with increasing count size. Log counts typically show a decreasing mean-variance trend. Voom estimates mean-variance trend for log2 cpm counts, then assigns a weight to each observation based on its predicted variance. The weights are then used in the linear modelling process to adjust for heteroscedasticity. \n",
    "\n",
    "**Limma-voom** is the tool of choice for DE because it:\n",
    "\n",
    "1. allows for flexible model specifications such that multiple categorical and continuous variables can be included.\n",
    "2. based on simulation studies, maintains the false discovery rate at or below the nominal rate\n",
    "3. Empirical Bayes smoothing of gene-wise standard deviations provides increased power.\n",
    "\n",
    "**References:** \n",
    "Law, C.W., Chen, Y., Shi, W. et al. voom: precision weights unlock linear model analysis tools for RNA-seq read counts. Genome Biol 15, R29 (2014). https://doi.org/10.1186/gb-2014-15-2-r29 </br>\n",
    "https://rdrr.io/bioc/limma/man/voom.html </br>\n",
    "https://ucdavis-bioinformatics-training.github.io/2018-June-RNA-Seq-Workshop/thursday/DE.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y$samples\n",
    "y$samples$group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the model to be fitted. We do this before using voom since voom uses variances of the model residuals (observed - fitted)\n",
    "#### a model where each coefficient corresponds to a group mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#design = model.matrix(~0 + my_targets$group + my_targets$batch,  data= y$samples)\n",
    "design = model.matrix(~0 + y$samples$group,  data= y$samples)\n",
    "design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colnames(design) <- c(\"Hrt_ctrl\",\"Hrt_drug\");design\n",
    "colnames(design) <- c(\"Msle_ctrl\",\"Msle_drug\");design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contrasts <- makeContrasts(Drug_vs_Ctrl=Hrt_drug-Hrt_ctrl, levels=colnames(design));contrasts\n",
    "contrasts <- makeContrasts(Drug_vs_Ctrl=Msle_drug-Msle_ctrl, levels=colnames(design));contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v <- voom(y, design, plot=FALSE)\n",
    "vfit<-lmFit(v, design)\n",
    "vfit<-contrasts.fit(vfit,contrasts=contrasts)\n",
    "results <-eBayes(vfit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is voom doing?\n",
    "\n",
    "<ul>\n",
    "    <li>Counts are transformed to log2 counts per million reads (CPM), where “per million reads” is defined based on the normalization factors we calculated earlier</li>\n",
    "    <li>A linear model is fitted to the log2 CPM for each gene, and the residuals are calculated </li>\n",
    "    <li>A smoothed curve is fitted to the sqrt(residual standard deviation) by average expression (see red line in plot above) </li>\n",
    "    <li>The smoothed curve is used to obtain weights for each gene and sample that are passed into limma along with the log2 CPMs. </li>\n",
    "</ul>\n",
    "\n",
    "#### add figure\n",
    "\n",
    "The above is a “good” voom plot. If your voom plot looks like the below, you might want to filter more:\n",
    "\n",
    "### Empirical Bayes smoothing of standard errors\n",
    "#### shrinks standard errors that are much larger or smaller than those from other genes towards the average standard error\n",
    "\n",
    "## Reference:\n",
    "https://genomebiology.biomedcentral.com/articles/10.1186/gb-2014-15-2-r29 <br />\n",
    "https://www.degruyter.com/doi/10.2202/1544-6115.1027\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "png(file.path(\".\", \"01_voom.png\"),units=\"in\", width=10, height=5, res=1000, pointsize=12)\n",
    "par(mfrow=c(1,2))\n",
    "   voom(y,design=design, normalize.method=\"none\", plot=TRUE, save.plot=TRUE)\n",
    "   plotSA(results, main=\"Final Model\")\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotSA(results, main=\"Final Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats <- topTable(results, coef=1, n=Inf, adjust.method=\"BH\", sort.by=\"none\", p.value=1, lfc=0); dim(stats)\n",
    "results$stats <- stats\n",
    "sig <- topTable(results, coef=1, n=Inf, adjust.method=\"BH\", sort.by=\"none\", p.value=0.05, lfc=1); dim(sig)\n",
    "dt <- decideTests(results, method=\"separate\", adjust.method=\"BH\", p.value=0.05, lfc = 1)\n",
    "summary(dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "\n",
    "write.csv(stats,\"stats.csv\")\n",
    "write.csv(sig,\"sig.csv\")\n",
    "write.csv(summary(dt), \"dt_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li> <b>logFC:</b> log2 fold change of drug/control </li>\n",
    "    <li> <b>AveExpr:</b> Average expression across all samples, in log2 CPM </li>\n",
    "    <li> <b>t:</b> logFC divided by its standard error </li>\n",
    "    <li> <b>P.Value:</b> Raw p-value (based on t) from test that logFC differs from 0 </li>\n",
    "    <li> <b>adj.P.Val:</b> Benjamini-Hochberg false discovery rate adjusted p-value </li>\n",
    "    <li> <b>B:</b> log-odds that gene is DE (arguably less useful than the other columns) </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png(file.path(\".\", paste(\"05_\",\"drug_vs_CON\", \"_p-value.histogram.png\",sep=\"\")), units=\"in\", width=6, height=5, res=1000, pointsize=12)\n",
    "{\n",
    "   grayblue <-\"#b0ddf5\"\n",
    "      \n",
    "     hist(results$stats$P.Value, col= grayblue, breaks = 100, \n",
    "          main=paste(\"P-value Histogram: \",\"drug vs. CON\",sep=\"\"),\n",
    "          xlab=\"P.Value\", \n",
    "          ylab=\"frequency\", \n",
    "          font=1, cex.main=1, las=1)\n",
    "}\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     hist(results$stats$P.Value, col= grayblue, breaks = 100, \n",
    "          main=paste(\"P-value Histogram: \",\"drug vs. CON\",sep=\"\"),\n",
    "          xlab=\"P.Value\", \n",
    "          ylab=\"frequency\", \n",
    "          font=1, cex.main=1, las=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i<-1\n",
    "\n",
    "png(file.path(\".\", paste(\"07_\",\"Drug_vs_CON\",\"_MD.plot.png\",sep=\"\")), units=\"in\", width=5, height=5, res=1000, pointsize=10)\n",
    "{\n",
    "     ##----------------------------------------------------------------------------\n",
    "     op <- par(no.readonly = TRUE)  # save current par settings b4 plotting\n",
    "     #par(mfrow = c(4, 5))          # multiple plots\n",
    "     par(mar = c(5, 5, 4, 1))       # inner margin (bottom, left, top, right)\n",
    "     par(mgp = c(3, 1, 0))          # axis margin (labels, ticks, line)\n",
    "     par(oma = c(2, 1, 0, 1))       # outer margin (bottom, left, top, right)\n",
    "     ##----------------------------------------------------------------------------\n",
    "     plotMD(results, column=i, cex=1, las=1, status=dt[,i], values=c(1,-1), col=c(\"red\",\"blue\"), \n",
    "            legend=\"topright\", main=\"\", \n",
    "            xlab=expression(paste(\"avg. \", log[2],\" (counts-per-million)\",sep=\"\")),\n",
    "            ylab=expression(paste(log[2],\" (fold-change)\",sep=\"\")),\n",
    "            cex.axis=1.1, cex.lab=1.2\n",
    "            # ,ylim=c(-11,13)\n",
    "            #,xlim=c(2,14)\n",
    "     )\n",
    "     title(main=paste(\"MD plot: \", \"Drug vs. CON\", \"\", sep=\"\"))\n",
    "     legend(\"topright\", c(\"up\", \"not sig.\", \"down\"), inset=0, pch=19,\n",
    "            box.col=\"black\", box.lwd=1, bg=\"white\",\n",
    "            col=c(\"red\",\"black\",\"blue\"), ncol=1, cex=1)\n",
    "     \n",
    "     # text(x=12, y=-3, label=paste(\"up =\", summary(dt)[3], sep=\" \"), adj=0, col=\"red\", cex=0.9, font=1)\n",
    "     # text(x=12, y=-4, label=paste(\"not sig. =\", summary(dt)[2], sep=\" \"), adj=0, col=\"black\", cex=0.9, font=1)\n",
    "     # text(x=12, y=-5, label=paste(\"down =\", summary(dt)[1], sep=\" \"), adj=0, col=\"blue\", cex=0.9, font=1)\n",
    "     abline(h=c(-1,1), col=\"black\", lty=2,lwd=1)\n",
    "}\n",
    "\n",
    "\n",
    "dev.off()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i<-1\n",
    "\n",
    "     ##----------------------------------------------------------------------------\n",
    "     op <- par(no.readonly = TRUE)  # save current par settings b4 plotting\n",
    "     #par(mfrow = c(4, 5))          # multiple plots\n",
    "     par(mar = c(5, 5, 4, 1))       # inner margin (bottom, left, top, right)\n",
    "     par(mgp = c(3, 1, 0))          # axis margin (labels, ticks, line)\n",
    "     par(oma = c(2, 1, 0, 1))       # outer margin (bottom, left, top, right)\n",
    "     ##----------------------------------------------------------------------------\n",
    "     plotMD(results, column=i, cex=1, las=1, status=dt[,i], values=c(1,-1), col=c(\"red\",\"blue\"), \n",
    "            legend=\"topright\", main=\"\", \n",
    "            xlab=expression(paste(\"avg. \", log[2],\" (counts-per-million)\",sep=\"\")),\n",
    "            ylab=expression(paste(log[2],\" (fold-change)\",sep=\"\")),\n",
    "            cex.axis=1.1, cex.lab=1.2\n",
    "            # ,ylim=c(-11,13)\n",
    "            #,xlim=c(2,14)\n",
    "     )\n",
    "     title(main=paste(\"MD plot: \", \"drug vs. CON\", \"\", sep=\"\"))\n",
    "     legend(\"topright\", c(\"up\", \"not sig.\", \"down\"), inset=0, pch=19,\n",
    "            box.col=\"black\", box.lwd=1, bg=\"white\",\n",
    "            col=c(\"red\",\"black\",\"blue\"), ncol=1, cex=1)\n",
    "     \n",
    "     # text(x=12, y=-3, label=paste(\"up =\", summary(dt)[3], sep=\" \"), adj=0, col=\"red\", cex=0.9, font=1)\n",
    "     # text(x=12, y=-4, label=paste(\"not sig. =\", summary(dt)[2], sep=\" \"), adj=0, col=\"black\", cex=0.9, font=1)\n",
    "     # text(x=12, y=-5, label=paste(\"down =\", summary(dt)[1], sep=\" \"), adj=0, col=\"blue\", cex=0.9, font=1)\n",
    "     abline(h=c(-1,1), col=\"black\", lty=2,lwd=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(Glimma, quietly=TRUE)\n",
    "  \n",
    "glMDPlot(results, \n",
    "         coef=i,\n",
    "         counts = norm_lcpm, \n",
    "         anno = results$genes,\n",
    "        # groups = my_targets$group,\n",
    "         groups = y$samples$group,\n",
    "         samples = colnames(norm_lcpm), \n",
    "         status = dt[,i],\n",
    "         transform=FALSE, \n",
    "         main = paste(\"MD Plot: \",\"drug vs. CON\", \"\", sep=\" \"),\n",
    "         xlab = \"avg. log2 (counts-per-million)\",\n",
    "         ylab = \"log2 (fold-change)\", \n",
    "         side.xlab = \"group\",\n",
    "         side.ylab = \"expression (norm_lcpm)\", \n",
    "         side.log = FALSE,\n",
    "         # side.gridstep = ifelse(!transform || side.log, FALSE, 0.5),\n",
    "         p.adj.method = \"BH\",\n",
    "         jitter = 30, \n",
    "         side.main = \"SYMBOL\",\n",
    "         display.columns = colnames(results$genes), \n",
    "         cols = c(\"#00bfff\", \"#858585\", \"#ff3030\"),\n",
    "         #sample.cols = colors[my_targets$group],\n",
    "         path = file.path(\".\"),\n",
    "         folder = \"MD-plots\", \n",
    "         html = paste(\"drug_vs_CON\", \"_MD.plot\", sep=\"\"), \n",
    "         launch = FALSE\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png(file.path(\".\", paste(\"08_\",\"drug_vs_CON\",\"_volcano.plot.png\",sep=\"\")), units=\"in\", width=6, height=6, res=1000, pointsize=12)\n",
    "{\n",
    "     with(results$stats, \n",
    "          plot(logFC, -log10(adj.P.Val),# pch=20, las=1,\n",
    "               pch = 21, bg = \"black\", col = \"black\", lwd = 0.9, cex = 1,\n",
    "               main=paste(\"Volcano Plot: \", \"drug vs. CON\",\"\", sep=\" \"), \n",
    "               xlab=expression(paste(,log[2],\" (fold-change)\",sep=\"\")),\n",
    "               #xlab= \"logFC\", \n",
    "               ylab=expression(paste(\"-\",log[10],\" (adj. p-value)\",sep=\"\"))\n",
    "               # ylab=\"-log10 (P.Value)\", \n",
    "               # ,ylim= c(0, 8)\n",
    "               , xlim= c(-2,7)\n",
    "               , cex.axis=1.1, cex.lab=1.2\n",
    "          )\n",
    "     )\n",
    "     # grid()\n",
    "     \n",
    "     with(subset(results$stats, adj.P.Val <= 0.05 & logFC >= 1), points(logFC, -log10(adj.P.Val), pch = 21, bg = \"firebrick2\", col = \"firebrick2\", lwd = 1, cex = 1.1))\n",
    "     with(subset(results$stats, adj.P.Val <= 0.05 & logFC <= -1), points(logFC, -log10(adj.P.Val), pch = 21, bg = \"blue\", col = \"blue\", lwd = 1, cex = 1.1))\n",
    "\n",
    "     abline(v= c(-1,1), col=\"black\", lty=2, lwd=1)\n",
    "     abline(h= -log10(0.05), col=\"black\", lty=2, lwd=1)\n",
    "     \n",
    "     # text(x=-14, y=8, label=paste(\"up = \", summary(dt)[3], sep=\" \"), adj=0, col=\"red\", cex=0.8, font=1)\n",
    "     # text(x=-14, y=7.5, label=paste(\"not sig = \", summary(dt)[2], sep=\" \"), adj=0, col=\"black\", cex=0.8, font=1)\n",
    "     # text(x=-14, y=7, label=paste(\"down = \", summary(dt)[1], sep=\" \"), adj=0, col=\"blue\", cex=0.8, font=1)\n",
    "}\n",
    "\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glXYPlot(x=results$stats$logFC,\n",
    "         y=-log(results$stats$adj.P.Val, 10),\n",
    "         counts = norm_lcpm,\n",
    "         #groups = my_targets$group,\n",
    "         #samples = rownames(my_targets),\n",
    "         groups = y$samples$group,\n",
    "         samples = rownames(y$samples),\n",
    "         status = dt[,i], \n",
    "         transform=FALSE, \n",
    "         anno = results$genes,\n",
    "         display.columns = colnames(results$genes),\n",
    "         xlab = \"log2 (fold-change)\",\n",
    "         ylab = \"-log10 (adj. p-value)\",\n",
    "         side.main = \"SYMBOL\",\n",
    "         side.xlab = \"group\",\n",
    "         side.ylab = \"expression (norm_lcpm)\",\n",
    "         side.log=FALSE,\n",
    "         #sample.cols = colors[my_targets$group],\n",
    "         cols = c(\"#00bfff\", \"#858585\", \"#ff3030\"),\n",
    "         p.adj.method=\"BH\",\n",
    "         jitter = 30,\n",
    "         path = file.path(\".\"),\n",
    "         folder = \"Volcano-plots\",\n",
    "         html = paste(\"drug_vs_CON\",\"_volcano.plot\", sep=\"\"),\n",
    "         main=paste(\"Volcano Plot: \",\"drug vs. CON\", \"\", sep=\" \"),\n",
    "         launch = FALSE\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check have same samples and order\n",
    "ncol(y$counts)\n",
    "length(y$samples)\n",
    "colnames(y$counts)\n",
    "colnames(norm_lcpm)\n",
    "rownames(y$samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTES\n",
    "\n",
    "### Question 1: Can you export normalized counts from edgeR DGElist\n",
    "\n",
    " If you want to export normalized expression values, just use cpm or rpkm. \n",
    " The root of the confustion is there is no such thing as a **TMM normalized count** because TMM normalizes the library sizes rather than the counts. A normalized value can no longer be a count. \n",
    "\n",
    "**TMM** normalizes the library sizes to produce effective library sizes. </br>\n",
    "**CPM** values are counts normalized by the effective library sizes. </br>\n",
    "**RPKM** values are counts normalized by effective library sizes and by gene/feature length. \n",
    "\n",
    "Secondly, people assume edgeR must be storing **normalized counts** internally, but it does not. Most edgeR DE pipelines never modify the original counts in any way.\n",
    "\n",
    "#### Normalization for library size is instead implicit as part of the model-fitting. edgeR does not use cpm or rpkm values internally in its DE pipelines, rather they are only for export or for graphical purposes. \n",
    "\n",
    "A third source of confusion is that the original edgeR pipeline (**classic** pipeline) did compute pseudo.counts internally, which are equivalent to the original counts but with equalized effective library sizes. \n",
    "The pseudo.counts were used only to estimate dispersions, not to assess DE or to compute fold-changes. We did not intend or recommend that users would export these as normalized values but some have done so.  It is not appropriate to multiple pseudo.counts by norm.factors as one blog suggests. \n",
    "\n",
    "#### Examples of posts by edgeR authors:\n",
    "https://support.bioconductor.org/p/133671/ </br>\n",
    "https://support.bioconductor.org/p/46779/ </br>\n",
    "https://www.biostars.org/p/9475236/ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download folders from On demand\n",
    "# open terminal and change to the directory of the files to save. \n",
    "\n",
    "zip -r filename.zip /path/directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
